{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다양한 임베딩 모델을 평가하는 구체적인 방법을 알려드리도록 하겠습니다\n",
    "- 임베딩 후보 리스트 준비 (OpenAI, Cohere, e5-base-v2)\n",
    "- 활용하고자 하는 데이터셋을 임베딩 변환\n",
    "- Test set 랜덤 선별 후 평가 지표 생성\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import cohere\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from tqdm.notebook import tqdm\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# initialize openai\n",
    "os.environ['OPENAI_API_KEY']= \"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\"\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# initialize cohere\n",
    "os.environ[\"CO_API_KEY\"] = \"KfiaxhA9zulTfhPEmSqZmh3JFMClCLBAj4hmCY3E\"\n",
    "co = cohere.Client()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"quora_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = df.loc[2, 'text']\n",
    "print(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = df.loc[3, 'text']\n",
    "print(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(txt_list, provider='openai'):\n",
    "    if provider=='openai':\n",
    "        client = OpenAI()\n",
    "\n",
    "        response = client.embeddings.create(\n",
    "        input=txt_list,\n",
    "        model=\"text-embedding-3-small\")\n",
    "        responses = [r.embedding for r in response.data]\n",
    "\n",
    "        return responses\n",
    "    \n",
    "    elif provider=='cohere':\n",
    "        doc_embeds = co.embed(\n",
    "        txt_list,\n",
    "        input_type=\"search_document\",\n",
    "        model=\"embed-english-v3.0\")\n",
    "        return doc_embeds.embeddings\n",
    "    else:\n",
    "        assert False, \"Double check provider name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb1 = create_embeddings(df.loc[2, 'text'])\n",
    "emb2 = create_embeddings(df.loc[3, 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simarity between two embeddings\n",
    "print(\"Cosine 유사도 : {}.\\n사용된 문장 : \\n{}\\n{}\".format(cosine_similarity(emb1[0], emb2[0]), text1, text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text3 = df.loc[4, 'text']\n",
    "\n",
    "emb3 = create_embeddings(text3)\n",
    "print(\"Cosine 유사도 : {}.\\n사용된 문장 : \\n{}\\n{}\".format(cosine_similarity(emb1[0], emb3[0]), text1, text3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text4 = df.loc[6, 'text']\n",
    "\n",
    "emb3 = create_embeddings(text4)\n",
    "print(\"Cosine 유사도 : {}.\\n사용된 문장 : \\n{}\\n{}\".format(cosine_similarity(emb1[0], emb3[0]), text1, text4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Embedding vector Dataset 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "openai embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create embeddings (openai)\n",
    "# (비용 발생 주의)\n",
    "openai_emb = create_embeddings(df.text.tolist(), provider='openai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['openai_emb'] = openai_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cohere embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create embeddings (cohere)\n",
    "# (비용 발생 주의)\n",
    "cohere_emb = create_embeddings(df.text.tolist(), 'cohere')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['cohere_emb'] = cohere_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e5 embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load gpu if possible\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model_id = \"intfloat/e5-base-v2\"\n",
    "\n",
    "# init tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModel.from_pretrained(model_id).to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_e5_emb(docs, model):\n",
    "    \"\"\"\n",
    "    e5 embedding 모델을 활용하여 임베딩 벡터 생성\n",
    "    \"\"\"\n",
    "    docs = [f\"query: {d}\" for d in docs]\n",
    "    # tokenize\n",
    "    tokens = tokenizer(\n",
    "        docs, padding=True, max_length=512, truncation=True, return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "    with torch.no_grad():\n",
    "        out = model(**tokens)\n",
    "        last_hidden = out.last_hidden_state.masked_fill( # from last hidden state\n",
    "            ~tokens[\"attention_mask\"][..., None].bool(), 0.0\n",
    "        )\n",
    "        # average out embeddings per token (non-padding)\n",
    "        doc_embeds = last_hidden.sum(dim=1) / tokens[\"attention_mask\"].sum(dim=1)[..., None]\n",
    "    return doc_embeds.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "긴 runtime 주의 (약 2시간)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = df.text.tolist()\n",
    "# batch_size = 128\n",
    "\n",
    "# for i in tqdm(range(0, len(data), batch_size)):\n",
    "#     i_end = min(len(data), i+batch_size)\n",
    "#     data_batch = data[i:i_end]\n",
    "#     # embed current batch\n",
    "#     embed_batch = create_e5_emb(data_batch)\n",
    "#     if i == 0:\n",
    "#         emb3 = embed_batch.copy()\n",
    "#     else:\n",
    "#         emb3 = np.concatenate([emb3, embed_batch.copy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emb3 = [list(e) for e in emb3]\n",
    "# df['e5_emb'] = emb3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"quora_dataset_emb.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "embedding이 이미 처리된 데이터 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"quora_dataset_emb.csv\")\n",
    "# str -> list 형태로 변환\n",
    "import json\n",
    "df['openai_emb'] = df['openai_emb'].apply(json.loads)\n",
    "df['cohere_emb'] = df['cohere_emb'].apply(json.loads)\n",
    "df['e5_emb'] = df['e5_emb'].apply(json.loads)\n",
    "df['duplicated_questions'] = df['duplicated_questions'].apply(json.loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Test set 선별"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테스팅을 위해 필요한 랜덤 질문들 선별"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now choose random 10 rows of answers\n",
    "test_query = random.choices(df.id, k=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df.loc[df.id.isin(test_query)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 테스트 질문별로 가장 유사한 질문들 top-k개 retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def search_top_k(search_df, search_df_column, id, topk):\n",
    "    \"\"\"\n",
    "    search_df : search를 할 대상 dataframe\n",
    "    search_df_column : search를 위해 사용될 embedding column name\n",
    "    id : test query id\n",
    "    topk : 유사도 기반으로 top-k개 선별\n",
    "    \"\"\"\n",
    "    query = search_df.loc[search_df['id']==id, search_df_column].values[0]\n",
    "    query_reshaped = np.array(query).reshape(1, -1)\n",
    "    \n",
    "    search_df = search_df.loc[search_df['id']!=id]\n",
    "    # cosine similarity in batch\n",
    "    similarities = cosine_similarity(query_reshaped, np.vstack(search_df[search_df_column].values)).flatten()\n",
    "    \n",
    "    search_df['similarity'] = similarities\n",
    "    \n",
    "    # Get top-k indices\n",
    "    # hence we sort the topk indices again to ensure they are truly the top-k\n",
    "    topk_indices = np.argpartition(similarities, -topk)[-topk:]\n",
    "    topk_indices_sorted = topk_indices[np.argsort(-similarities[topk_indices])]\n",
    "    \n",
    "    # Retrieve the top-k results\n",
    "    search_result = search_df.iloc[topk_indices_sorted]\n",
    "    \n",
    "    return search_result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 각 테스트 질문당 데이터 전체를 대상으로 cosine_similarity를 계산하고\n",
    "- openai embedding, cohere embedding에 대해 각각 질문 k 개씩 진행\n",
    "- search_result format :\n",
    "```json\n",
    "{\n",
    "    'question id' : cosine_sim 기준 유사한 질문 top-k개를 담은 pd.DataFrame,\n",
    "    'question id' : ...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 질문들 중, test 질문과 동일한 질문이 가장 유사하게 도출될 것이기 때문에\n",
    "# test 질문을 제외한 top-5\n",
    "query_results_openai = { k:search_top_k(df, 'openai_emb', k, 5) for k in test.id }\n",
    "query_results_cohere = { k:search_top_k(df, 'cohere_emb', k, 5) for k in test.id }\n",
    "query_results_e5 = { k:search_top_k(df, 'e5_emb', k, 5) for k in test.id }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테스트 결과 엿보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[test.length==3].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[test['id']==14182, 'text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_results_openai[14182]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Scoring function 정의\n",
    "\n",
    "- 각 질문별로 accuracy score 부여\n",
    "    - Accuracy score : 현재 유사하다고 태그된 질문들 중 몇 개가 실제 유사한 질문들인가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_accuracy(full_df, tmp_df, test_id):\n",
    "    \"\"\"\n",
    "    각 테스트 질문과 유사하다고 판단된 질문들 중, 실제 duplicated_questions에 들어있는 질문들을 count\n",
    "    \"\"\"\n",
    "    duplicated_questions = full_df.loc[full_df['id'] == test_id, 'duplicated_questions'].values[0]\n",
    "\n",
    "    # 본인 ID는 제외\n",
    "    filtered_df = tmp_df[tmp_df['id'] != test_id]\n",
    "    # 현재 retrieve 해온 ID들이, 테스트 질문 내에 들어있는 아이디들인지 count\n",
    "    match_count = filtered_df['id'].isin(duplicated_questions).sum()\n",
    "\n",
    "    # Calculate the accuracy in terms of percentage\n",
    "    if filtered_df.shape[0]<len(duplicated_questions):\n",
    "        percentage = (match_count / filtered_df.shape[0])\n",
    "    else:\n",
    "        percentage = (match_count / len(duplicated_questions))\n",
    "    return percentage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_openai = [score_accuracy(df, query_results_openai[i], i) for i in query_results_openai.keys()]\n",
    "accuracy_cohere = [score_accuracy(df, query_results_cohere[i], i) for i in query_results_cohere.keys()]\n",
    "accuracy_e5 = [score_accuracy(df, query_results_e5[i], i) for i in query_results_e5.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(accuracy_openai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(accuracy_cohere)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(accuracy_e5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "오답 엿보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [index for index, value in enumerate(accuracy_openai) if value <= 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(query_results_openai.keys())[60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[test['id']==985]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[test['id']==984]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_results_openai[985]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 결론\n",
    "\n",
    "- cohere, openai, e5 모두 굉장히 성능이 좋기 때문에 대부분의 task에 곧바로 활용해도 무방함.\n",
    "- Local embedding 모델을 활용하고자 할 때 위와 같은 방법으로 classification 성능 & 자원 할당 체크 필요.\n",
    "- 성능 평가 방법\n",
    "    - 태깅된 데이터 셋 활용\n",
    "    - 정성적 평가\n",
    "        - 데이터 태깅을 할 노동력이 부족할 때\n",
    "        - 태깅을 하기 애매한 분야 (정답이 없는 경우)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--END--"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastcampus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
