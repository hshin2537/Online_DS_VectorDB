{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V100","authorship_tag":"ABX9TyPtmwu3TEJ/F6Cfv/ddxOjV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"AwKHtjLtbkyM"},"outputs":[],"source":["\n","!pip install datasets transformers torch accelerate"]},{"cell_type":"code","source":["from datasets import load_dataset\n","dataset_train = load_dataset(\"keremberke/shoe-classification\",'full', split='train')"],"metadata":{"id":"6EnFrOfCb7VS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#사전학습 Vision 트랜스포머 불러오기\n","from transformers import ViTFeatureExtractor, ViTForImageClassification\n","from sklearn.neighbors import NearestNeighbors\n","import torch\n","\n","# import model - https://huggingface.co/google/vit-base-patch16-224-in21k\n","model_id = 'google/vit-base-patch16-224-in21k'\n","\n","model_vanilla = ViTForImageClassification.from_pretrained(model_id)\n","feature_extractor_vanilla = ViTFeatureExtractor.from_pretrained(model_id)"],"metadata":{"id":"CLg4ntLNb7SK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_vanilla"],"metadata":{"id":"uJoLZDFsb7Pq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["feature_extractor_vanilla"],"metadata":{"id":"coB7QCR7b7Mh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_vanilla.classifier = torch.nn.Identity()"],"metadata":{"id":"FMaA93oCb7Ju"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","def extract_embeddings(dataset, model, feature_extractor):\n","    model.eval()\n","    embeddings = []\n","    with torch.no_grad():\n","        for item in dataset:\n","            inputs = feature_extractor(images=item['image'], return_tensors=\"pt\")\n","            outputs = model(**inputs)\n","            embeddings.append(outputs.logits.squeeze().numpy())\n","    return embeddings"],"metadata":{"id":"QPiTrf1Rb7G7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","def retrieve_images(index, nn_model, dataset, embeddings):\n","    index = int(index)\n","    distances, indices = nn_model.kneighbors([embeddings[index]])\n","\n","    indexed_distances = [(int(i), dist) for i, dist in zip(indices[0], distances[0]) if i != index]\n","\n","    indexed_distances.sort(key=lambda x: x[1])\n","\n","    retrieved_images = [dataset[idx][\"image\"] for idx, _ in indexed_distances]\n","    return retrieved_images\n","\n","def show_images(dataset, num_images=5):\n","    fig, axes = plt.subplots(1, num_images, figsize=(15, 3))\n","    for i in range(num_images):\n","        img = dataset[\"train\"][i][\"image\"]\n","        axes[i].imshow(img)\n","        axes[i].axis('off')\n","    plt.show()"],"metadata":{"id":"fVcGUj7Ab7EF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","embeddings_vanilla = extract_embeddings(dataset_train, model_vanilla, feature_extractor_vanilla)\n","nn_model_vanilla = NearestNeighbors(n_neighbors=6, algorithm='ball_tree')\n","nn_model_vanilla.fit(embeddings_vanilla)"],"metadata":{"id":"8jo1ax5Qb7BR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","import matplotlib.pyplot as plt\n","test_index =358\n","retrieved_images = retrieve_images(test_index, nn_model_vanilla, dataset_train, embeddings_vanilla)\n","\n","plt.imshow(dataset_train[test_index][\"image\"])\n","plt.title(\"Test Image\")\n","plt.axis('off')\n","plt.show()\n","\n","show_images({\"train\": [{\"image\": img} for img in retrieved_images]})"],"metadata":{"id":"IRQr_pYQb6-J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","test_index = 65\n","retrieved_images = retrieve_images(test_index, nn_model_vanilla, dataset_train, embeddings_vanilla)\n","\n","plt.imshow(dataset_train[test_index][\"image\"])\n","plt.title(\"Test Image\")\n","plt.axis('off')\n","plt.show()\n","\n","show_images({\"train\": [{\"image\": img} for img in retrieved_images]})"],"metadata":{"id":"zizlP-ecb679"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","test_index = 94\n","retrieved_images = retrieve_images(test_index, nn_model_vanilla, dataset_train, embeddings_vanilla)\n","\n","plt.imshow(dataset_train[test_index][\"image\"])\n","plt.title(\"Test Image\")\n","plt.axis('off')\n","plt.show()\n","\n","show_images({\"train\": [{\"image\": img} for img in retrieved_images]})"],"metadata":{"id":"IUI4x2P5b642"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Fine-Tuning\n","dataset_test = load_dataset(\"keremberke/shoe-classification\",'full', split='validation')"],"metadata":{"id":"V34RSjI1b62F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","def preprocess(batch):\n","    inputs = feature_extractor_vanilla(\n","        batch['image'],\n","        return_tensors='pt'\n","    )\n","    inputs['labels'] = batch['labels']\n","    return inputs"],"metadata":{"id":"QF7QkANVb6lK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","train_prepared = dataset_train.with_transform(preprocess)\n","test_prepared = dataset_test.with_transform(preprocess)"],"metadata":{"id":"6hnG9uUPcRxu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","def collate_batch(batch):\n","    pixel_vals = [item['pixel_values'] for item in batch]\n","    labels = [item['labels'] for item in batch]\n","    return {'pixel_values': torch.stack(pixel_vals), 'labels': torch.tensor(labels)}"],"metadata":{"id":"IRoxx955cRu8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from datasets import load_metric\n","\n","accuracy_metric = load_metric(\"accuracy\")\n","\n","def evaluate_model_performance(outputs):\n","    predicted_labels = np.argmax(outputs.predictions, axis=1)\n","    true_labels = outputs.label_ids\n","    return accuracy_metric.compute(predictions=predicted_labels, references=true_labels)"],"metadata":{"id":"vC0MvY_RcRsZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","num_labels_in_dataset = len(set(dataset_train['labels']))\n","label_names = dataset_train.features['labels'].names\n","\n","num_labels_in_dataset, label_names"],"metadata":{"id":"AVIMxfbjcRpo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = ViTForImageClassification.from_pretrained(\n","    model_id,\n","    num_labels=num_labels_in_dataset\n",")"],"metadata":{"id":"fRi0EHVpcRmy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model"],"metadata":{"id":"neVgHHeGcRjq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"],"metadata":{"id":"RoX3hS4ycRhK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","import transformers\n","from transformers import TrainingArguments\n","\n","training_args = TrainingArguments(\n","  output_dir=\"./shoe\",\n","  per_device_train_batch_size=16,\n","  evaluation_strategy=\"steps\",\n","  num_train_epochs=10,\n","  save_steps=20,\n","  eval_steps=20,\n","  logging_steps=20,\n","  learning_rate=0.0002,\n","  save_total_limit=2,\n","  remove_unused_columns=False,\n","  push_to_hub=False,\n","  #load_best_model_at_end=True,\n",")"],"metadata":{"id":"4g9aovv2cbxF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.to(device)"],"metadata":{"id":"vrOe3_g9cbue"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","from transformers import Trainer\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=collate_batch,\n","    compute_metrics=evaluate_model_performance,\n","    train_dataset=train_prepared,\n","    eval_dataset=test_prepared,\n","    tokenizer=feature_extractor_vanilla,\n",")"],"metadata":{"id":"xpo-OvtWcbrv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","training_outcome = trainer.train()\n","trainer.save_model()\n","\n","training_metrics = training_outcome.metrics\n","trainer.log_metrics(\"training\", training_metrics)\n","trainer.save_metrics(\"training\", training_metrics)\n","\n","trainer.save_state()"],"metadata":{"id":"fn-ruGzmcbnt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","evaluation_metrics = trainer.evaluate(test_prepared)\n","\n","trainer.log_metrics(\"evaluation\", evaluation_metrics)\n","trainer.save_metrics(\"evaluation\", evaluation_metrics)"],"metadata":{"id":"Cg0oJYE2SIdk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","fine_tuned_path = './shoe'\n","model_finetuned = ViTForImageClassification.from_pretrained(fine_tuned_path)\n","feature_extractor_finetuned = ViTFeatureExtractor.from_pretrained(fine_tuned_path)\n","model_finetuned.classifier = torch.nn.Identity()\n","\n","embeddings_ft = extract_embeddings(dataset_train, model_finetuned, feature_extractor_finetuned)\n","\n","nn_model_ft = NearestNeighbors(n_neighbors=6, algorithm='ball_tree')\n","nn_model_ft.fit(embeddings_ft)"],"metadata":{"id":"y3oN636CSIYZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","test_index = 94\n","retrieved_images = retrieve_images(test_index, nn_model_ft, dataset_train,embeddings_ft)\n","plt.imshow(dataset_train[test_index][\"image\"])\n","plt.title(\"Test Image\")\n","plt.axis('off')\n","plt.show()\n","\n","show_images({\"train\": [{\"image\": img} for img in retrieved_images]})"],"metadata":{"id":"V9Em6xwuSIVY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_index = 358\n","retrieved_images = retrieve_images(test_index, nn_model_ft, dataset_train,embeddings_ft)\n","plt.imshow(dataset_train[test_index][\"image\"])\n","plt.title(\"Test Image\")\n","plt.axis('off')\n","plt.show()\n","\n","show_images({\"train\": [{\"image\": img} for img in retrieved_images]})"],"metadata":{"id":"r7d9HVhbSIR_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_index = 174\n","retrieved_images = retrieve_images(test_index, nn_model_ft, dataset_train,embeddings_ft)\n","plt.imshow(dataset_train[test_index][\"image\"])\n","plt.title(\"Test Image\")\n","plt.axis('off')\n","plt.show()\n","\n","show_images({\"train\": [{\"image\": img} for img in retrieved_images]})"],"metadata":{"id":"KLStaVbNSIOt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_index =383\n","retrieved_images = retrieve_images(test_index, nn_model_ft, dataset_train,embeddings_ft)\n","plt.imshow(dataset_train[test_index][\"image\"])\n","plt.title(\"Test Image\")\n","plt.axis('off')\n","plt.show()\n","\n","show_images({\"train\": [{\"image\": img} for img in retrieved_images]})"],"metadata":{"id":"hBMRlM6MSILe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_index = 65\n","retrieved_images = retrieve_images(test_index, nn_model_ft, dataset_train,embeddings_ft)\n","plt.imshow(dataset_train[test_index][\"image\"])\n","plt.title(\"Test Image\")\n","plt.axis('off')\n","plt.show()\n","\n","show_images({\"train\": [{\"image\": img} for img in retrieved_images]})"],"metadata":{"id":"ldyHeiM1SIIY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"x6TgXrpDSIE3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"rq0Jmkh8SICJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"54D5-6WpSH_T"},"execution_count":null,"outputs":[]}]}