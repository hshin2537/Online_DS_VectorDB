{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPnVWvphhiQPqb0MO0fnOOO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### Part 3. Langchain - VectorDB 이용한 간단한 RAG 구현\n","- Objectives: Langchain+파인콘으로 간단한 위키문서 upsert 및 이를 기반으로 하는 naive-RAG 구현"],"metadata":{"id":"Kf_EyiLXdGzQ"}},{"cell_type":"code","source":[],"metadata":{"id":"nbl3exNie9fa"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T4XHPnIJtEky"},"outputs":[],"source":["!pip install langchain pinecone-client datasets openai tiktoken"]},{"cell_type":"code","source":["import os\n","\n","import time\n","os.environ['PINECONE_API_KEY']='<YOUR_API_KEY>'\n","os.environ['OPENAI_API_KEY']='<YOUR_API_KEY>'\n","pinecone_api_key = os.environ.get('PINECONE_API_KEY')\n","openai_api_key = os.environ.get('OPENAI_API_KEY')"],"metadata":{"id":"Cn98Y_LBuKQN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#https://huggingface.co/datasets/lcw99/wikipedia-korean-20221001/viewer/default/train\n","# 사용 데이터 로드\n","from datasets import load_dataset\n","dataset = load_dataset(\"lcw99/wikipedia-korean-20221001\", split='train[:100]')"],"metadata":{"id":"I5ckQrXkuy3e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset[0]"],"metadata":{"id":"FNnljQDUX2fC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 텍스트 스플리터 기능을 활용한 데이터 문서 청킹 작업 정의\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","\n","text_splitter = RecursiveCharacterTextSplitter(\n","    chunk_size=400,\n","    chunk_overlap=20,\n","    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",")"],"metadata":{"id":"OVAHfSY226y7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"bfLcbEYHYNW-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 정의한 청킹 방식으로 어떤 식으로 짤라지는지 확인.\n","text_splitter.split_text(dataset[0]['text'])[:5]"],"metadata":{"id":"82YzU7ED26wb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 청크 단위 임베딩이 필요하므로 임베딩 벡터 불러오기\n","from langchain.embeddings.openai import OpenAIEmbeddings\n","\n","model_name = 'text-embedding-ada-002'\n","\n","embed = OpenAIEmbeddings(\n","    model=model_name,\n","    openai_api_key=openai_api_key\n",")"],"metadata":{"id":"WMEYiXtd26t8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","from pinecone import Pinecone, PodSpec\n","\n","api_key = os.getenv(\"PINECONE_API_KEY\")\n","\n","pc = Pinecone(api_key=api_key)"],"metadata":{"id":"8til815_26o-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from time import sleep\n","\n","index_name = 'quickstart'\n","dimension = 1536\n","metric = 'dotproduct'\n","spec = PodSpec('gcp-starter')\n","\n","if index_name in [index_info[\"name\"] for index_info in pc.list_indexes()]:\n","    pc.delete_index(index_name)\n","\n","pc.create_index(index_name, dimension=dimension, metric=metric, spec=spec)\n","\n","while not pc.describe_index(index_name).status['ready']:\n","    sleep(1)\n","index = pc.Index(index_name)\n","sleep(1)\n","index_stats = index.describe_index_stats()\n","print(index_stats)"],"metadata":{"id":"tzTdAsHXcLbE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tqdm.auto import tqdm\n","from uuid import uuid4\n","\n","def process_and_upload_records(dataset, batch_limit=100):\n","    texts = []\n","    metadatas = []\n","\n","    for i, record in enumerate(tqdm(dataset)):\n","        metadata = {\n","            'id': str(record['id']),\n","            'source': record['url'],\n","            'title': record['title']\n","        }\n","\n","        record_texts = text_splitter.split_text(record['text'])\n","        record_metadatas = [\n","            {\"chunk\": j, \"text\": text, **metadata}\n","            for j, text in enumerate(record_texts)\n","        ]\n","\n","        texts.extend(record_texts)\n","        metadatas.extend(record_metadatas)\n","\n","        if len(texts) >= batch_limit:\n","            upload_data(texts, metadatas)\n","            texts, metadatas = [], []\n","\n","    if texts:\n","        upload_data(texts, metadatas)\n","\n","def upload_data(texts, metadatas):\n","    ids = [str(uuid4()) for _ in range(len(texts))]\n","    embeds = embed.embed_documents(texts)\n","    index.upsert(vectors=zip(ids, embeds, metadatas))\n","\n","process_and_upload_records(dataset)\n"],"metadata":{"id":"3VQR0p8Qcd9A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 잘 올라가졌는지 확인\n","index.describe_index_stats()"],"metadata":{"id":"M8ZWPF77Z5AV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#파인콘 api로 기반 문서들 업서트 이후에는 이제 랭체인에서 이를 활용하기 위해 벡터스토어 오브젝트로 연결시켜줌\n","from langchain.vectorstores import Pinecone\n","\n","text_field = \"text\"\n","\n","vectorstore = Pinecone(\n","    index, embed.embed_query, text_field\n",")"],"metadata":{"id":"tGBRL9HAu5SQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 단순 retrieval\n","query = \"지미 카터가 누구야?\"\n","\n","vectorstore.similarity_search(\n","    query,\n","    k=3\n",")"],"metadata":{"id":"4fqf6Jou6K37"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# full RAG 구성\n","from langchain.chat_models import ChatOpenAI\n","from langchain.chains import RetrievalQA\n","\n","llm = ChatOpenAI(\n","    openai_api_key=openai_api_key,\n","    model_name='gpt-3.5-turbo',\n","    temperature=0\n",")\n","\n","qa = RetrievalQA.from_chain_type(\n","    llm=llm,\n","    chain_type=\"stuff\",\n","    retriever=vectorstore.as_retriever()\n",")"],"metadata":{"id":"2KjSyFdSvDiK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 사용자 질문 -> similarity Search -> GPT 답안 생성\n","qa.run(query)"],"metadata":{"id":"q5Qzsbfj7et0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 못믿는 사람들을 위한 증거제시용 소스체인 구성\n","from langchain.chains import RetrievalQAWithSourcesChain\n","\n","qa_with_sources = RetrievalQAWithSourcesChain.from_chain_type(\n","    llm=llm,\n","    chain_type=\"stuff\",\n","    retriever=vectorstore.as_retriever()\n",")"],"metadata":{"id":"csnq_H5_vXR9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 소스체인 RAG 시험\n","qa_with_sources(query)"],"metadata":{"id":"N9b4Pfd6vyG2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9C04LE7I8Nhh"},"execution_count":null,"outputs":[]}]}