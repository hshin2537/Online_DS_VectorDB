{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import openai\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from image_utils import fetch_clip, draw_images\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# pandas dataframe display\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텍스트 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = pd.read_csv(\"attribute_specific.csv\")\n",
    "new_df = pd.read_csv(\"clothes_final2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pineconeDB에 upsert!!\n",
    "from pinecone import Pinecone\n",
    "\n",
    "pc = Pinecone(api_key=\"74e30e50-02fa-4e55-9bff-affa6a3817a0\")\n",
    "# index 개수 확인\n",
    "# index_list = pc.list_indexes().indexes\n",
    "\n",
    "# index description\n",
    "index = pc.Index(\"fastcampus\")\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize openai\n",
    "os.environ['OPENAI_API_KEY']= \"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\"\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, processor, tokenizer = fetch_clip(model_name=\"patrickjohncyh/fashion-clip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from search_utils import get_single_text_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"black dog\"\n",
    "\n",
    "d = get_single_text_embedding(input_text, model, tokenizer)\n",
    "\n",
    "result = index.query(\n",
    "    vector=d[0],\n",
    "    top_k=5,\n",
    "    # filter={\"category\": {\"$eq\": \"dress\"}},\n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "paths = [i['metadata']['img_path'] for i in result.matches]\n",
    "\n",
    "draw_images([Image.open(i) for i in paths])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 첫 gateway\n",
    "- 패션과 관련된 토픽인지 여부를 판단\n",
    "- semantic router도 사용 가능하지만, router를 지정해줘야 하기 때문에 한계가 있음 (27 classes)\n",
    "- 사용자의 인풋을 처음으로 받는 구간\n",
    "    - -> openai chat completion을 사용하여 사용자들의 text input이 실제 우리들이 받아서 처리할 내용인지 여부를 판단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List, Literal\n",
    "\n",
    "from llama_index.program.openai import OpenAIPydanticProgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize openai\n",
    "os.environ['OPENAI_API_KEY']= \"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\"\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-4-turbo-preview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_gateway_prompt = \"\"\"Input text : {text_input}\n",
    "Using the input text, do the following\n",
    "- clothes_topic : Determine whether the text describes a clothes. The output should be a python boolean.\n",
    "- fashion_item : Determine whether it mentions a specific fashion items such as boots or shirt, umbrella etc. The output should be a python boolean.\n",
    "\"\"\"\n",
    "\n",
    "class first_gateway(BaseModel):\n",
    "    \"Data model to determine whether the text describes a fashion type or clothes type.\"\n",
    "    clothes_topic: bool\n",
    "    fashion_item: bool\n",
    "\n",
    "program = OpenAIPydanticProgram.from_defaults(\n",
    "    output_cls=first_gateway, prompt_template_str=first_gateway_prompt, llm=llm,verbose=True\n",
    ")\n",
    "\n",
    "output = program(\n",
    "    text_input=\"street fashion\"\n",
    ")\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in ['bohemian style boots', 'old school', 'a cup of tea', 'umbrella', 'a black hat', 'suit and tie', 'wedding apparel',\n",
    "          '파란색 패션 양말', '자동차']:\n",
    "    print(t)\n",
    "    print(program(\n",
    "                text_input=t\n",
    "            ))\n",
    "    print(\"-\"*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 두 번째 gateway\n",
    "- 사용자들의 인풋을 우리가 원하는 인풋의 형태로 변형해주는 과정\n",
    "- 카테고리 강제를 통해 search space 제한"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"black jacket\"\n",
    "\n",
    "d = get_single_text_embedding(input_text, model, tokenizer)\n",
    "\n",
    "result = index.query(\n",
    "    vector=d[0],\n",
    "    top_k=10,\n",
    "    filter={\"category\": {\"$eq\": \"jacket\"}},\n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "paths = [i['metadata']['img_path'] for i in result.matches]\n",
    "\n",
    "draw_images([Image.open(i) for i in paths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"black jacket\"\n",
    "\n",
    "d = get_single_text_embedding(input_text, model, tokenizer)\n",
    "\n",
    "result = index.query(\n",
    "    vector=d[0],\n",
    "    top_k=10,\n",
    "    filter={\"category\": {\"$eq\": \"jacket\"}},\n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "paths = [i['metadata']['img_path'] for i in result.matches]\n",
    "\n",
    "draw_images([Image.open(i) for i in paths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_gateway_prompt = \"\"\"Input text : {text_input}.\n",
    "Using the input text, do the following.\n",
    "\n",
    "First, divide the items listed in the sentence, ensuring that descriptive words for each item are kept together during the separation.\n",
    "Second, for each item listed, do the following :\n",
    "    - Categorize the clothes type mentioned from the input.\n",
    "        - From the options below, choose the clothes type mentioned. : \n",
    "            'pants', 'shirt, blouse', 'jacket', 'top, t-shirt, sweatshirt',\n",
    "            'dress', 'shoe', 'glasses', 'skirt', 'bag, wallet', 'belt',\n",
    "            'headband, head covering, hair accessory', 'sock', 'hat', 'watch',\n",
    "            'glove', 'tights, stockings', 'sweater', 'tie', 'shorts', 'scarf',\n",
    "            'coat', 'vest', 'umbrella', 'cardigan', 'cape', 'jumpsuit',\n",
    "            'leg warmer'\n",
    "        - a suit is part of jacket\n",
    "        - If none of the above is mentioned, say \"None\"\n",
    "    - Refine the text into a comma-separated string of attributes\n",
    "        -  as an example, the text 'casual, urban-inspired jacket with bold graphics and loose-fitting designs'\n",
    "        would be converted to 'casual, urban-inspired, jacket, bold graphics, loose-fit'.\n",
    "        - another example, the text 'color Pink, - silhouette Straight, - silhouette_fit Loose'\n",
    "        would be converted to 'color pink, silhouette Straight, silhouette_fit Loose'.\n",
    "        - do not hesitate to repeat the modifiers for each item.\n",
    "The output should be in English.\n",
    "\"\"\"\n",
    "\n",
    "class second_gateway_list(BaseModel):\n",
    "    \"Data model to categorize the clothing type, and refine text into a specific format.\"\n",
    "    clothes_type: Literal['pants', 'shirt, blouse', 'jacket', 'top, t-shirt, sweatshirt',\n",
    "                            'dress', 'shoe', 'glasses', 'skirt', 'bag, wallet', 'belt',\n",
    "                            'headband, head covering, hair accessory', 'sock', 'hat', 'watch',\n",
    "                            'glove', 'tights, stockings', 'sweater', 'tie', 'shorts', 'scarf',\n",
    "                            'coat', 'vest', 'umbrella', 'cardigan', 'cape', 'jumpsuit',\n",
    "                            'leg warmer', \"None\"]\n",
    "    refined_text: str\n",
    "\n",
    "class second_gateway(BaseModel):\n",
    "    \"Data model to list items.\"\n",
    "    items: List[second_gateway_list]\n",
    "\n",
    "program = OpenAIPydanticProgram.from_defaults(\n",
    "    output_cls=second_gateway, prompt_template_str=second_gateway_prompt, llm=llm, verbose=False\n",
    ")\n",
    "\n",
    "output = program(\n",
    "    text_input=\"street fashion boots\"\n",
    ")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in ['bohemian style pants', 'street fashion', 'a black hat', 'suit and tie', 'wedding apparel',\n",
    "          '파란색 패션 양말', 'old school', 'umbrella']:\n",
    "    print(t)\n",
    "    print(program(\n",
    "                text_input=t\n",
    "            ))\n",
    "    print(\"-\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "third_gateway_prompt = \"\"\"Input text : {text_input}.\n",
    "Using the input text, do the following.\n",
    "    - Refine the text into a comma-separated string of attributes\n",
    "        -  as an example, the text 'casual, urban-inspired jacket with bold graphics and loose-fitting designs'\n",
    "        would be converted to 'casual, urban-inspired, jacket, bold graphics, loose-fit'\n",
    "        - do not hesitate to repeat the modifiers for each item.\n",
    "\"\"\"\n",
    "\n",
    "class third_gateway_list(BaseModel):\n",
    "    \"Data model to reformat an input text.\"\n",
    "    refined_text: str\n",
    "\n",
    "class third_gateway(BaseModel):\n",
    "    \"Data model to list items.\"\n",
    "    items: List[third_gateway_list]\n",
    "\n",
    "program = OpenAIPydanticProgram.from_defaults(\n",
    "    output_cls=third_gateway, prompt_template_str=third_gateway_prompt, llm=llm, verbose=False\n",
    ")\n",
    "\n",
    "output = program(\n",
    "    text_input=\"bohemian style clothes\"\n",
    ")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in ['bohemian style pants', 'street fashion', 'a black hat', 'suit and tie', 'wedding apparel',\n",
    "          '파란색 패션 양말', 'old school', 'umbrella', \"I want a black jacket with gold zippers\"]:\n",
    "    print(t)\n",
    "    print(program(\n",
    "                text_input=t\n",
    "            ))\n",
    "    print(\"-\"*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사용자 input 처리 경로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pass_first_gateway(input_text, llm, verbose=False):\n",
    "    first_gateway_prompt = \"\"\"Input text : {text_input}\n",
    "    Using the input text, do the following\n",
    "    - clothes_topic : Determine whether the subject it is related to fashion or clothes. The output should be a python boolean.\n",
    "    - Determine whether it mentions a specific fashion items such as boots or shirt, umbrella etc. The output should be a python boolean.\n",
    "    \"\"\"\n",
    "    \n",
    "    class first_gateway(BaseModel):\n",
    "        \"Data model to determine whether the text is related to clothes.\"\n",
    "        clothes_topic: bool\n",
    "        fashion_item: bool\n",
    "\n",
    "    program = OpenAIPydanticProgram.from_defaults(\n",
    "        output_cls=first_gateway, prompt_template_str=first_gateway_prompt, llm=llm,verbose=verbose\n",
    "    )\n",
    "\n",
    "    output = program(\n",
    "        text_input=input_text\n",
    "    )\n",
    "\n",
    "    return output.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pass_second_gateway(text_input, llm, verbose=False):\n",
    "    second_gateway_prompt = \"\"\"Input text : {text_input}.\n",
    "    Using the input text, do the following.\n",
    "\n",
    "    First, divide the items listed in the sentence, ensuring that descriptive words for each item are kept together during the separation.\n",
    "    Second, for each item listed, do the following :\n",
    "        - Categorize the clothes type mentioned from the input.\n",
    "            - From the options below, choose the clothes type mentioned. : \n",
    "                'pants', 'shirt, blouse', 'jacket', 'top, t-shirt, sweatshirt',\n",
    "                'dress', 'shoe', 'glasses', 'skirt', 'bag, wallet', 'belt',\n",
    "                'headband, head covering, hair accessory', 'sock', 'hat', 'watch',\n",
    "                'glove', 'tights, stockings', 'sweater', 'tie', 'shorts', 'scarf',\n",
    "                'coat', 'vest', 'umbrella', 'cardigan', 'cape', 'jumpsuit',\n",
    "                'leg warmer'\n",
    "            - a suit is part of jacket\n",
    "            - If none of the above is mentioned, say \"None\"\n",
    "        - Refine the text into a comma-separated string of attributes\n",
    "            -  as an example, the text 'casual, urban-inspired jacket with bold graphics and loose-fitting designs'\n",
    "            would be converted to 'casual, urban-inspired, jacket, bold graphics, loose-fit'.\n",
    "            - another example, the text 'color Pink, - silhouette Straight, - silhouette_fit Loose'\n",
    "            would be converted to 'color pink, silhouette Straight, silhouette_fit Loose'.\n",
    "            - do not hesitate to repeat the modifiers for each item.\n",
    "    The output should be in English.\n",
    "    \"\"\"\n",
    "\n",
    "    class second_gateway_list(BaseModel):\n",
    "        \"Data model to categorize the clothing type, and refine text into a specific format.\"\n",
    "        clothes_type: Literal['pants', 'shirt, blouse', 'jacket', 'top, t-shirt, sweatshirt',\n",
    "                            'dress', 'shoe', 'glasses', 'skirt', 'bag, wallet', 'belt',\n",
    "                            'headband, head covering, hair accessory', 'sock', 'hat', 'watch',\n",
    "                            'glove', 'tights, stockings', 'sweater', 'tie', 'shorts', 'scarf',\n",
    "                            'coat', 'vest', 'umbrella', 'cardigan', 'cape', 'jumpsuit',\n",
    "                            'leg warmer']\n",
    "        refined_text: str\n",
    "\n",
    "    class second_gateway(BaseModel):\n",
    "        \"Data model to list items.\"\n",
    "        items: List[second_gateway_list]\n",
    "\n",
    "    program = OpenAIPydanticProgram.from_defaults(\n",
    "        output_cls=second_gateway, prompt_template_str=second_gateway_prompt, llm=llm, verbose=verbose\n",
    "    )\n",
    "\n",
    "    output = program(\n",
    "        text_input=text_input\n",
    "    )\n",
    "\n",
    "    return output.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pass_third_gateway(text_input, llm, verbose=False):\n",
    "    \n",
    "    third_gateway_prompt = \"\"\"Input text : {text_input}.\n",
    "    Using the input text, do the following.\n",
    "        - Refine the text into a comma-separated string of attributes\n",
    "            -  as an example, the text 'casual, urban-inspired jacket with bold graphics and loose-fitting designs'\n",
    "            would be converted to 'casual, urban-inspired, jacket, bold graphics, loose-fit'\n",
    "            - do not hesitate to repeat the modifiers for each item.\n",
    "    \"\"\"\n",
    "\n",
    "    class third_gateway_list(BaseModel):\n",
    "        \"Data model to reformat an input text.\"\n",
    "        refined_text: str\n",
    "\n",
    "    class third_gateway(BaseModel):\n",
    "        \"Data model to list items.\"\n",
    "        items: List[third_gateway_list]\n",
    "\n",
    "    program = OpenAIPydanticProgram.from_defaults(\n",
    "        output_cls=third_gateway, prompt_template_str=third_gateway_prompt, llm=llm, verbose=verbose\n",
    "    )\n",
    "\n",
    "    output = program(\n",
    "        text_input=text_input\n",
    "    )\n",
    "    return output.dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search module과 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "- vans shoes\n",
    "\n",
    "=> {\"shoes\":'vans shoes'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def text_search(index, items_dict, model, tokenizer, splade_model, splade_tokenizer, top_k=10, hybrid=False):\n",
    "    search_results = dict()\n",
    "    for item in items_dict['items']:\n",
    "        text_emb = get_single_text_embedding(item['refined_text'], model, tokenizer)\n",
    "        if hybrid:\n",
    "            sparse_vector = gen_sparse_vector(item['refined_text'], splade_model, splade_tokenizer)\n",
    "        else:\n",
    "            sparse_vector=None\n",
    "        \n",
    "        if 'clothes_type' in list(item.keys()):\n",
    "            search_result = index.query(\n",
    "                            vector=text_emb[0],\n",
    "                            sparse_vector=sparse_vector,\n",
    "                            top_k=top_k,\n",
    "                            filter={\"category\": {\"$eq\": item['clothes_type']}},\n",
    "                            include_metadata=True\n",
    "                        )\n",
    "            search_results[item['clothes_type']] = search_result\n",
    "        else:\n",
    "            search_result = index.query(\n",
    "                            vector=text_emb[0],\n",
    "                            sparse_vector=sparse_vector,\n",
    "                            top_k=top_k,\n",
    "                            include_metadata=True\n",
    "                        )\n",
    "            search_results['all'] = search_result\n",
    "    return search_results\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from search_utils import text_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pineconeDB에 upsert!!\n",
    "from pinecone import Pinecone\n",
    "\n",
    "pc = Pinecone(api_key=\"74e30e50-02fa-4e55-9bff-affa6a3817a0\")\n",
    "# index 개수 확인\n",
    "# index_list = pc.list_indexes().indexes\n",
    "\n",
    "# index description\n",
    "index = pc.Index(\"fastcampus\")\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splade.splade.models.transformer_rep import Splade\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "splade_model_id = 'naver/splade-cocondenser-ensembledistil'\n",
    "\n",
    "splade_model = Splade(splade_model_id, agg='max')\n",
    "splade_model.to('cpu')\n",
    "splade_model.eval()\n",
    "\n",
    "splade_tokenizer = AutoTokenizer.from_pretrained(splade_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_utils import fetch_clip\n",
    "# fetch CLIP model\n",
    "model, processor, tokenizer = fetch_clip(model_name=\"patrickjohncyh/fashion-clip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "# initialize openai\n",
    "os.environ['OPENAI_API_KEY']= \"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\"\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "llm = OpenAI(model=\"gpt-4-turbo-preview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = \"Street fashioned boots and jacket, with colorful socks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_gateway_output = pass_first_gateway(example_text, llm)\n",
    "first_gateway_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_gateway_output = pass_second_gateway(example_text, llm)\n",
    "second_gateway_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_third_gateway(example_text, llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from search_utils import get_single_text_embedding, gen_sparse_vector\n",
    "from image_utils import draw_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define user journey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = \"Street fashioned boots and jacket, with colorful socks\"\n",
    "\n",
    "first_gateway_output = pass_first_gateway(example_text, llm)\n",
    "print(\"first_gateway_output : \", first_gateway_output)\n",
    "if (first_gateway_output['clothes_topic']):\n",
    "    print(\"Passed the first gateway. Moving on to the second gateway...\")\n",
    "    if (not first_gateway_output['fashion_item']):\n",
    "        \n",
    "        print(\"However, specific item is not found. Searching the whole database.\")\n",
    "        gateway_output = pass_third_gateway(example_text, llm)\n",
    "        filter=False\n",
    "    else:\n",
    "        gateway_output = pass_second_gateway(example_text, llm)\n",
    "        filter=True\n",
    "    search_results = text_search(index, gateway_output, model, tokenizer, splade_model, splade_tokenizer, top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = dict()\n",
    "for k,v in search_results.items():\n",
    "    paths[k] = [i['metadata']['img_path'] for i in v['matches']]\n",
    "\n",
    "for k,v in paths.items():\n",
    "    print(k)\n",
    "    draw_images([Image.open(i) for i in v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = \"street fashion\"\n",
    "\n",
    "first_gateway_output = pass_first_gateway(example_text, llm)\n",
    "\n",
    "if (first_gateway_output['clothes_topic']):\n",
    "    print(\"Passed the first gateway. Moving on to the second gateway...\")\n",
    "    if (not first_gateway_output['fashion_item']):\n",
    "        \n",
    "        print(\"However, specific item is not found. Searching the whole database.\")\n",
    "        gateway_output = pass_third_gateway(example_text, llm)\n",
    "        filter=False\n",
    "    else:\n",
    "        gateway_output = pass_second_gateway(example_text, llm)\n",
    "        filter=True\n",
    "    search_results = text_search(index, gateway_output, model, tokenizer, splade_model, splade_tokenizer, top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = dict()\n",
    "for k,v in search_results.items():\n",
    "    paths[k] = [i['metadata']['img_path'] for i in v['matches']]\n",
    "\n",
    "for k,v in paths.items():\n",
    "    print(k)\n",
    "    draw_images([Image.open(i) for i in v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fashion_query_transformer(text_input):\n",
    "\n",
    "    llm = OpenAI(model=\"gpt-4-turbo-preview\")\n",
    "\n",
    "    #### text가 패션과 관련된 항목인지 여부를 판단\n",
    "    first_gateway_output = pass_first_gateway(text_input, llm)\n",
    "    print(first_gateway_output)\n",
    "\n",
    "    if (first_gateway_output['clothes_topic']):\n",
    "        # print(\"Passed the first gateway. Moving on to the second gateway...\")\n",
    "        if (not first_gateway_output['fashion_item']):\n",
    "            # print(\"However, specific item is not found. Searching the whole database.\")\n",
    "            gateway_output = pass_third_gateway(text_input, llm)\n",
    "        else:\n",
    "            done=False\n",
    "            while not done:\n",
    "                try:\n",
    "                    gateway_output = pass_second_gateway(text_input, llm)\n",
    "                    done=True\n",
    "                except:\n",
    "                    continue\n",
    "    else:\n",
    "        return None\n",
    "    return gateway_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_search(index, items_dict, model, tokenizer, splade_model, splade_tokenizer, top_k=10, hybrid=False):\n",
    "    search_results = dict()\n",
    "    for item in items_dict['items']:\n",
    "        text_emb = get_single_text_embedding(item['refined_text'], model, tokenizer)\n",
    "        if hybrid:\n",
    "            sparse_vector = gen_sparse_vector(item['refined_text'], splade_model, splade_tokenizer)\n",
    "        else:\n",
    "            sparse_vector=None\n",
    "        \n",
    "        if 'clothes_type' in list(item.keys()):\n",
    "            search_result = index.query(\n",
    "                            vector=text_emb[0],\n",
    "                            sparse_vector=sparse_vector,\n",
    "                            top_k=top_k,\n",
    "                            filter={\"category\": {\"$eq\": item['clothes_type']}},\n",
    "                            include_metadata=True\n",
    "                        )\n",
    "            search_results[item['clothes_type']] = search_result\n",
    "        else:\n",
    "            search_result = index.query(\n",
    "                            vector=text_emb[0],\n",
    "                            sparse_vector=sparse_vector,\n",
    "                            top_k=top_k,\n",
    "                            include_metadata=True\n",
    "                        )\n",
    "            search_results['all'] = search_result\n",
    "    return search_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "- 패션과 무관한 텍스트 -> None\n",
    "- 패션 스타일 텍스트 -> hybrid search\n",
    "- 패션 아이템 텍스트 -> apply filter & hybrid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"a fluffy cat\"\n",
    "sparse_query = gen_sparse_vector(input, splade_model, splade_tokenizer)\n",
    "\n",
    "# 인풋을 체크 및 변환\n",
    "text_query = fashion_query_transformer(input)\n",
    "\n",
    "if text_query:\n",
    "    # search\n",
    "    result = text_search(index, text_query, model, tokenizer, splade_model, splade_tokenizer, top_k=10)\n",
    "\n",
    "    # 이미지들의 path 가져오기\n",
    "    paths = dict()\n",
    "    for k,v in result.items():\n",
    "        paths[k] = [i['metadata']['img_path'] for i in v['matches']]\n",
    "\n",
    "    # 이미지들 show\n",
    "    for k,v in paths.items():\n",
    "        print(k)\n",
    "        draw_images([Image.open(i) for i in v])\n",
    "else:\n",
    "    print(\"패션과 무관한 텍스트 입니다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"vans shoes with formal suit and a red tie for a wedding\"\n",
    "text_query = fashion_query_transformer(input)\n",
    "\n",
    "if text_query:\n",
    "    print(text_query)\n",
    "    # search\n",
    "    sparse_query = gen_sparse_vector(input, splade_model, splade_tokenizer)\n",
    "    result = text_search(index, text_query, model, tokenizer, splade_model, splade_tokenizer, top_k=10)\n",
    "\n",
    "    # 이미지들의 path 가져오기\n",
    "    paths = dict()\n",
    "    for k,v in result.items():\n",
    "        paths[k] = [i['metadata']['img_path'] for i in v['matches']]\n",
    "\n",
    "    # 이미지들 show\n",
    "    for k,v in paths.items():\n",
    "        print(k)\n",
    "        draw_images([Image.open(i) for i in v])\n",
    "else:\n",
    "    print(text_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"creative fashion\"\n",
    "\n",
    "# 인풋을 체크 및 변환\n",
    "text_query = fashion_query_transformer(input)\n",
    "\n",
    "if text_query:\n",
    "    # search\n",
    "    result = text_search(index, text_query, model, tokenizer, splade_model, splade_tokenizer, top_k=10)\n",
    "\n",
    "    # 이미지들의 path 가져오기\n",
    "    paths = dict()\n",
    "    for k,v in result.items():\n",
    "        paths[k] = [i['metadata']['img_path'] for i in v['matches']]\n",
    "\n",
    "    # 이미지들 show\n",
    "    for k,v in paths.items():\n",
    "        print(k)\n",
    "        draw_images([Image.open(i) for i in v])\n",
    "else:\n",
    "    print(text_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fashion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
